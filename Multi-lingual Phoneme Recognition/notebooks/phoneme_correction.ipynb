{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/Projects/Project-On-Voice-Assistant/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "from xls_r_decoder.wav2phonemes import recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 4,\n",
    "    'phonemes': 392\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/boris/Projects/МИиМИС/Курсовая/speech_recognition/data/dataset.csv').values.tolist()\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1)\n",
    "train_df, val_df = train_test_split(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_df, params[\"batch_size\"], True)\n",
    "val_loader = DataLoader(val_df, params[\"batch_size\"], True)\n",
    "test_loader = DataLoader(test_df, params[\"batch_size\"], True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see what is the type of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, we've `ids: list[int], texts: list['str'], normal: list[str], abnormal: list[str]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = \"? абвгдеёжзийклмнопрстуфхшщчцьыъэюя\"\n",
    "def vectorize(labels: tuple[str]):\n",
    "    lengths = torch.LongTensor(size=(len(labels),))\n",
    "    # letters = torch.zeros(size=(len(labels),  max(map(len, labels)), len(abc)), dtype=float)\n",
    "    letters = torch.zeros(size=(len(labels),  max(map(len, labels))), dtype=float)\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        lengths[i] = len(label)\n",
    "        j=0\n",
    "        for c in label.lower():\n",
    "            if not c in abc:\n",
    "                lengths[i]-=1\n",
    "            else:\n",
    "                # letters[i,j, abc.index(c)]=1\n",
    "                letters[i,j]= abc.index(c)\n",
    "                j+=1\n",
    "    \n",
    "    return letters, lengths\n",
    "def decode(X):\n",
    "    r = []\n",
    "    for i in range(X.shape[0]):\n",
    "        s = []\n",
    "        for j in range(X.shape[1]):\n",
    "            if X[i,j] > 0:\n",
    "                s.append(abc[X[i,j]])\n",
    "        r.append(''.join(s))\n",
    "    return r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of preprocess correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCorrector(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(params['phonemes']+32, 32)\n",
    "\n",
    "        self.sigmoid1=nn.Tanh()\n",
    "        self.fc2=nn.Linear(32, len(abc))\n",
    "        # self.lstm = nn.RNN(len(abc), len(abc)//4, batch_first=True, num_layers=2)\n",
    "        # self.fc = nn.Linear(len(abc)//4, len(abc))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X: batch len classes\n",
    "        hidden = torch.zeros((X.shape[0], X.shape[1], 32))\n",
    "        for i in range(X.shape[1]):\n",
    "            k = torch.cat((X[:, i, :], hidden[:,max(0, i-1),:]), 1)\n",
    "            hidden[:, i, :] = self.fc1(k)\n",
    "        \n",
    "        X = self.fc2(hidden)\n",
    "\n",
    "        X = self.fc1(X)\n",
    "        X = self.sigmoid1(X)\n",
    "        # X, _ = self.lstm(X)\n",
    "        X = self.fc(X)\n",
    "        X = F.log_softmax(X, dim=-1)\n",
    "        return X.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMCorrector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CTCLoss(zero_infinity=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10/129 [01:18<15:04,  7.60s/it, loss=tensor(0.3721)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нннннннннннннннннннннннннннннннннннннннннннкннннннннннннннннкннннннннннннннннннннннннннннкнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n",
      "нннннннннннннннкнннннннннннннньнннннннннннньнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннднннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n",
      "ннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннкннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n",
      "нннннннннннннннннкннннннннннннньннннннннннннннннкннннннннннннннннннннннннннннннннннннннннннвнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 20/129 [02:42<16:22,  9.01s/it, loss=tensor(0.3347)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n",
      "нннннннннннннннннннннннннмннннннннннннкннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннньннннннннннннннкннннннннннннннннннннннннкнннннннннннннннмннннннннннннннннннннннннннннннннннннннн\n",
      "ннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннкннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n",
      "ннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннкннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 30/129 [04:00<14:08,  8.57s/it, loss=tensor(0.4888)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ккккккккккккккккнннкнкннннннннннньннннкккккккккннкннннньнннкккккьнннкккккккккккккккккккккккккнннньнннннннннннмннннккккккккккнккккккккккккккккккккккккккнннккккккккккккккккккккннннннккннкккккккккккккннннкнннкмнмннкккнннмнннккккккккккккккккккккккккккккккккккккккккк\n",
      "нкккккннмннннкккккккккккккккккннкнннннннккккккккккккккккккккккккккккккккккккнкккккккккккннннннннккккккккккнккккккккккккккнккнвнннннннннннннннннннннннннннннккккккккккккккккккннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннккккккккк\n",
      "нкнннкккккккккккккккккккннкккккккннкмннннкккккккнннньнннккккккккккнннкккннннннккккккккккккккккккккккккккккккккккккккккккккккккннннннккккннккккккккккккккккккккккннннкнннннннкккккккккккннннккккккккккккккккккккккккккнккккккккннннккнкккннннкннмнннккккккккккккккккккк\n",
      "кккккккккккнннннннккнннккккккккккккккккккккккккккккккннннннннннннннннннннккккккккккккккккккккккнннннннмннннннннккккккккккнннннннннннкккккккккккккккккккннннннннннннннккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккккк\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 40/129 [05:27<12:04,  8.14s/it, loss=tensor(0.3501)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ннннннннннннннннннннннннмнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннкнннкннннннннкннннннннннккнннннннннннккннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннкннннннннкнкнннннкннннннннн\n",
      "ннннннннннннмннннннннннннкнннннннннннннннннннннннннкннннннннннннннннннннннннннннннннннннннннннннннннннннннннйннннннннннннннкнннннннннннннкннннннкннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n",
      "ннннннннннннннннннннннннннннкннннннннннннннннннннньннннннннннннннвннннннннннннннкнннннннкннннннннннннннннкнннннвнннннннннннннннннннннннкнннннннннннннннннннннннннннкннннннннннкнннннннннннннннннннннннннннкннннннвннннннннннннкннннннннннннннннннннннн\n",
      "ннннннннннннннннннннннннннккнннннннннкннннннннннкннннннннннкнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннкннннннннннннннннннннннкннкнкнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 50/129 [06:42<08:22,  6.36s/it, loss=tensor(0.4949)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннньнннннннннннннннннннннннннннннннннннннннннннннкнннннннннннннннкнннннннннннкннннннннннннннннннннннннннннннннннннннн\n",
      "нннннннннннннннньннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n",
      "нннннннннннннннннннннннннньнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннкннннннннннньннннннннннннннннннннннннннннннннннннннннн\n",
      "ннннннннннннннннннньнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 60/129 [08:15<09:10,  7.97s/it, loss=tensor(0.4478)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ннннннннннннннннннннннннннннннннньнннннннннннннннннкннннннннннннннннннннннннннньннвннннннннннннннннннннннннннннннннннннннннннннннннн\n",
      "нннннннннннннннннннкнннннннннннннннньннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n",
      "нннннннннннннннннннннннннннннкннннннннннньннннннннннньнннннннннннннднннннддннннннннннннннннннньннннннннннннннннннннннннннннннннннннн\n",
      "нннннннннннннннннньннннннннннннннкннннннннннннннннннннннннннннннннннньнннннннннннннннннннннннннннннннннннннннннннннннннннннннннннннн\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 63/129 [08:42<09:48,  8.92s/it, loss=tensor(0.2749)]"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    print(f'epoch {epoch}/5')\n",
    "    epoch_loss = 0.0\n",
    "    nb=0\n",
    "    nb_raw = 0\n",
    "    for b in (pbar := tqdm.tqdm(train_loader, leave=False)):\n",
    "        labels, lengths = vectorize(b[1])\n",
    "        phonemes = recognize(b[3])\n",
    "        prediction = model(phonemes)\n",
    "        \n",
    "        ilengths = lengths.clone()\n",
    "        for i in range(prediction.shape[1]):\n",
    "            ilengths[i] = prediction.shape[0]\n",
    "        lv = loss(prediction, labels, ilengths, lengths)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        lv.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "        nb += sum(lengths)\n",
    "        epoch_loss += lv.item()\n",
    "\n",
    "        pbar.set_postfix({\"loss\": epoch_loss/nb})\n",
    "\n",
    "        nb_raw+=1\n",
    "        if nb_raw%10==0:\n",
    "            epoch_loss=0.0\n",
    "            nb=0\n",
    "            print(*decode((prediction.argmax(dim=2)).permute(1,0)), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(prediction, labels, lengths, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4830, -3.8087, -3.6947,  ..., -3.5795, -3.9501, -3.8384],\n",
       "        [-4.4772, -4.9877, -4.9001,  ..., -4.6272, -5.3549, -4.9898],\n",
       "        [-5.4203, -5.9879, -5.9463,  ..., -5.5983, -6.5168, -6.0107],\n",
       "        ...,\n",
       "        [-5.9518, -6.5256, -6.5254,  ..., -6.1657, -7.1658, -6.5898],\n",
       "        [-5.9518, -6.5256, -6.5254,  ..., -6.1657, -7.1658, -6.5898],\n",
       "        [-5.9518, -6.5256, -6.5254,  ..., -6.1657, -7.1658, -6.5898]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:,0,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
